"""
download_coco_async.py
å¼‚æ­¥é«˜é€Ÿä¸‹è½½COCOäººè½¦åˆ†ç±»å›¾ç‰‡
"""
"""
download_coco_fixed.py
ä¿®å¤Windowsä¸Šäº‹ä»¶å¾ªç¯é—®é¢˜çš„ä¸‹è½½è„šæœ¬
"""

import asyncio
import aiohttp
import pandas as pd
import os
import sys
from tqdm import tqdm
import time

class AsyncCOCODownloader:
    def __init__(self, max_concurrent=100, timeout=30):
        self.max_concurrent = max_concurrent
        self.timeout = timeout
        
    async def download_image(self, session, url, save_path, semaphore):
        """å¼‚æ­¥ä¸‹è½½å•ä¸ªå›¾ç‰‡"""
        async with semaphore:
            if os.path.exists(save_path):
                return {'status': 'skipped', 'size': 0, 'file': os.path.basename(save_path)}
            
            try:
                async with session.get(url, timeout=self.timeout) as response:
                    if response.status == 200:
                        content = await response.read()
                        with open(save_path, 'wb') as f:
                            f.write(content)
                        return {
                            'status': 'success',
                            'size': len(content),
                            'file': os.path.basename(save_path)
                        }
                    else:
                        return {
                            'status': f'failed_http_{response.status}',
                            'size': 0,
                            'file': os.path.basename(save_path)
                        }
            except asyncio.TimeoutError:
                return {'status': 'failed_timeout', 'size': 0, 'file': os.path.basename(save_path)}
            except Exception as e:
                return {'status': f'failed_{str(e)[:30]}', 'size': 0, 'file': os.path.basename(save_path)}
    
    async def download_batch(self, df, output_dir, desc="ä¸‹è½½è¿›åº¦"):
        """å¼‚æ­¥ä¸‹è½½ä¸€æ‰¹å›¾ç‰‡"""
        os.makedirs(output_dir, exist_ok=True)
        
        semaphore = asyncio.Semaphore(self.max_concurrent)
        
        connector = aiohttp.TCPConnector(limit=self.max_concurrent)
        timeout = aiohttp.ClientTimeout(total=self.timeout)
        
        async with aiohttp.ClientSession(connector=connector, timeout=timeout) as session:
            tasks = []
            for _, row in df.iterrows():
                save_path = os.path.join(output_dir, row['file_name'])
                task = self.download_image(session, row['coco_url'], save_path, semaphore)
                tasks.append(task)
            
            results = []
            with tqdm(total=len(tasks), desc=desc) as pbar:
                for coro in asyncio.as_completed(tasks):
                    result = await coro
                    results.append(result)
                    pbar.update(1)
            
            return results
    
    def download_dataset(self, csv_file, output_dir, dataset_name="æ•°æ®é›†"):
        """ä¸‹è½½æ•´ä¸ªæ•°æ®é›†"""
        print(f"\n{'='*60}")
        print(f"å¼€å§‹ä¸‹è½½ {dataset_name}")
        print(f"{'='*60}")
        
        try:
            df = pd.read_csv(csv_file)
            print(f"ğŸ“ æ–‡ä»¶: {csv_file}")
            print(f"ğŸ“Š å›¾ç‰‡æ•°é‡: {len(df):,}å¼ ")
            print(f"ğŸ“‚ è¾“å‡ºç›®å½•: {output_dir}")
        except Exception as e:
            print(f"âŒ åŠ è½½CSVå¤±è´¥: {e}")
            return None
        
        os.makedirs(output_dir, exist_ok=True)
        
        # ä¿®å¤ï¼šWindowsä¸Šæ­£ç¡®å¤„ç†äº‹ä»¶å¾ªç¯
        start_time = time.time()
        
        # æ–¹æ³•1ï¼šå°è¯•è·å–ç°æœ‰å¾ªç¯ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»ºæ–°å¾ªç¯
        try:
            loop = asyncio.get_event_loop()
        except RuntimeError:
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
        
        # æ£€æŸ¥å¾ªç¯æ˜¯å¦åœ¨è¿è¡Œ
        if loop.is_running():
            # å¦‚æœå¾ªç¯å·²ç»åœ¨è¿è¡Œï¼Œä½¿ç”¨ä¸åŒçš„æ–¹æ³•
            print("âš ï¸  äº‹ä»¶å¾ªç¯å·²åœ¨è¿è¡Œï¼Œä½¿ç”¨nest_asyncioè§£å†³...")
            try:
                import nest_asyncio
                nest_asyncio.apply()
            except ImportError:
                print("æ­£åœ¨å®‰è£…nest_asyncio...")
                import subprocess
                subprocess.check_call([sys.executable, "-m", "pip", "install", "nest_asyncio"])
                import nest_asyncio
                nest_asyncio.apply()
        
        # è¿è¡Œå¼‚æ­¥ä»»åŠ¡
        try:
            results = loop.run_until_complete(
                self.download_batch(df, output_dir, desc=f"{dataset_name}ä¸‹è½½è¿›åº¦")
            )
        except RuntimeError as e:
            if "already running" in str(e):
                # å¦‚æœè¿˜æœ‰é—®é¢˜ï¼Œä½¿ç”¨asyncio.runï¼ˆPython 3.7+ï¼‰
                print("ä½¿ç”¨asyncio.run()...")
                results = asyncio.run(self.download_batch(df, output_dir, desc=f"{dataset_name}ä¸‹è½½è¿›åº¦"))
            else:
                raise
        
        end_time = time.time()
        
        # ç»Ÿè®¡ç»“æœ
        success = sum(1 for r in results if r['status'] == 'success')
        skipped = sum(1 for r in results if r['status'] == 'skipped')
        failed = len(results) - success - skipped
        
        total_time = end_time - start_time
        speed = success / total_time if total_time > 0 else 0
        
        print(f"\nğŸ“ˆ {dataset_name}ä¸‹è½½å®Œæˆ!")
        print(f"   âœ… æˆåŠŸ: {success:,}å¼ ")
        print(f"   â­ï¸  è·³è¿‡: {skipped:,}å¼ ")
        print(f"   âŒ å¤±è´¥: {failed:,}å¼ ")
        print(f"   â±ï¸  è€—æ—¶: {total_time:.1f}ç§’ ({total_time/60:.1f}åˆ†é’Ÿ)")
        print(f"   ğŸš€ é€Ÿåº¦: {speed:.1f}å¼ /ç§’ ({speed*3600:.0f}å¼ /å°æ—¶)")
        
        if failed > 0:
            print(f"\nâš ï¸  å¤±è´¥è¯¦æƒ…ï¼ˆå‰10ä¸ªï¼‰:")
            failed_items = [r for r in results if r['status'].startswith('failed')]
            for i, r in enumerate(failed_items[:10]):
                print(f"   {i+1}. {r['file']}: {r['status']}")
        
        return {
            'success': success,
            'skipped': skipped,
            'failed': failed,
            'time': total_time,
            'speed': speed
        }

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ COCOäººè½¦åˆ†ç±»å›¾ç‰‡å¼‚æ­¥ä¸‹è½½å·¥å…·ï¼ˆWindowsä¿®å¤ç‰ˆï¼‰")
    print("="*60)
    
    # é…ç½®å‚æ•°
    config = {
        'max_concurrent': 100,  # Windowså»ºè®®ä¸è¦å¤ªé«˜
        'timeout': 30,
    }
    
    # æ–‡ä»¶è·¯å¾„é…ç½®
    datasets = [
        {
            'name': 'è®­ç»ƒé›†',
            'csv_file': 'coco_person_car_train.csv',
            'output_dir': 'coco/images/person_car_train2017',
            'new_csv': 'coco_person_car_train_local.csv'
        },
        {
            'name': 'éªŒè¯é›†', 
            'csv_file': 'coco_person_car_val.csv',
            'output_dir': 'coco/images/person_car_val2017',
            'new_csv': 'coco_person_car_val_local.csv'
        }
    ]
    
    # æ£€æŸ¥CSVæ–‡ä»¶
    for dataset in datasets:
        if not os.path.exists(dataset['csv_file']):
            print(f"âŒ æ‰¾ä¸åˆ°CSVæ–‡ä»¶: {dataset['csv_file']}")
            print("è¯·å…ˆè¿è¡Œæ•°æ®é›†æ„å»ºè„šæœ¬ç”ŸæˆCSVæ–‡ä»¶")
            sys.exit(1)
    
    # åˆ›å»ºä¸‹è½½å™¨
    downloader = AsyncCOCODownloader(
        max_concurrent=config['max_concurrent'],
        timeout=config['timeout']
    )
    
    total_stats = {
        'total_images': 0,
        'total_success': 0,
        'total_failed': 0,
        'total_time': 0
    }
    
    # ä¸‹è½½æ‰€æœ‰æ•°æ®é›†
    for dataset in datasets:
        stats = downloader.download_dataset(
            csv_file=dataset['csv_file'],
            output_dir=dataset['output_dir'],
            dataset_name=dataset['name']
        )
        
        if stats:
            # æ›´æ–°CSVè·¯å¾„
            df = pd.read_csv(dataset['csv_file'])
            df['file_path'] = df['file_name'].apply(
                lambda x: os.path.join(dataset['output_dir'], x)
            )
            df.to_csv(dataset['new_csv'], index=False)
            print(f"\nğŸ“„ å·²æ›´æ–°CSVè·¯å¾„: {dataset['new_csv']}")
            
            # ç´¯è®¡ç»Ÿè®¡
            total_stats['total_success'] += stats['success']
            total_stats['total_failed'] += stats['failed']
            total_stats['total_time'] += stats['time']
            
            df_size = len(pd.read_csv(dataset['csv_file']))
            total_stats['total_images'] += df_size
    
    # æ€»ä½“ç»Ÿè®¡
    print(f"\n{'='*60}")
    print("ğŸ‰ å…¨éƒ¨ä¸‹è½½å®Œæˆ!")
    print(f"{'='*60}")
    print(f"ğŸ“Š æ€»ä½“ç»Ÿè®¡:")
    print(f"   æ€»å›¾ç‰‡æ•°: {total_stats['total_images']:,}å¼ ")
    print(f"   æˆåŠŸä¸‹è½½: {total_stats['total_success']:,}å¼ ")
    print(f"   ä¸‹è½½å¤±è´¥: {total_stats['total_failed']:,}å¼ ")
    print(f"   æ€»è€—æ—¶: {total_stats['total_time']/60:.1f}åˆ†é’Ÿ")
    
    print(f"\nğŸ“ ç›®å½•ç»“æ„:")
    print(f"   coco/images/person_car_train2017/")
    print(f"   coco/images/person_car_val2017/")
    
    print(f"\nğŸ“„ ç”Ÿæˆçš„CSVæ–‡ä»¶:")
    print(f"   coco_person_car_train_local.csv")
    print(f"   coco_person_car_val_local.csv")
    
    print(f"\nâœ… å¯ä»¥å¼€å§‹è®­ç»ƒäº†!")

if __name__ == "__main__":
    # æ£€æŸ¥ä¾èµ–
    try:
        import aiohttp
        import pandas
        from tqdm import tqdm
    except ImportError as e:
        print(f"âŒ ç¼ºå°‘ä¾èµ–åº“: {e}")
        print("è¯·å®‰è£…: pip install aiohttp pandas tqdm")
        sys.exit(1)
    
    # è¿è¡Œä¸»å‡½æ•°
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ä¸‹è½½è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ ä¸‹è½½å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()